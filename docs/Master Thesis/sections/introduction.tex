\documentclass[../main]{subfiles}

\begin{document}

Nowadays computer vision is a widely used technology. It has started developing since the late 1960s but a real leap into the future has been done in 1990s, when a lot of research topics got a second chance, for instance, projective 3D reconstruction, camera calibration, multi-view stereo techniques and etc. On the other side, hardware world was rapidly evolving which resulted to the current situation in computer vision field of research. Today the level of development (\ac{IoT} devices, smart phones, tablets and etc.) allow to integrate computer vision tightly into humans life. There can be enormous amount of examples like parking systems when there is a camera mounted on a barrier at an entrance of a parking and a car number is recognized with this camera to decide whether the barrier will be opened or not; cameras mounted on the roads for catching speeding offenders; OCR technologies for analyzing text on images which allows to take a picture of a document and receive a typed version of it without typing by yourself; applications for finding pedestrians on a road; applications for face recognition, they help to find criminals in the streets, airports or any public place where cameras are mounted; this list can be almost infinite.

Human need for these technologies motivates researches to develop new techniques, improve algorithms that already exist and that what we have for the past decade. This decade changed the world, there have been created dozens of new concepts like social media, video platforms, 3d printing, cameras in mobile phones and etc. All of these have made a great influence on a human life. Peoples appetite is growing significantly and that is why new entertainment systems appear. Microsoft created Kinect, Sony has Move, Nintendo has Remote Plus and such kind of tools are based on computer vision but the technologies beneath them are not ideal, they need to gather a lot of data with a good quality, proceed complex computations and the result is not always as good as expected. All of that leads to the creation of new algorithms and attempts to get as much as possible of existing hardware. 

\subsection{Problem statement}

Tools mentioned above allow to capture objects movements, recognize patterns and etc. With their help it is possible to analyze density of an image, create a 3d reconstruction, control game objects with our hands moving, shaking and many other interactive activity became real. But what if we look closer at Kinect and Move; it is clearly seen that they are just an expensive set of sensors for computer vision but in addition to multiple cameras they have infrared sensors, color sensors, depth sensors, microphones and so on; all these sets of sensors allow them to gather a huge amount of data. From this perspective, even the simplest algorithms may provide quite a good result but what if we do not have such an expensive hardware; that is the case where algorithmic part takes the leading role.

There are dozens of different algorithms already invented, some of them are applicable to the nowadays situation and some of them need an improvement. Algorithms could have concrete purpose at the beginning but with a time they might be applied to other field and become a real breakthrough there. This thesis will focus on experiments with the algorithms that allow to get the same result as with Kinect or another expensive hardware while having a simple monocular camera. These experiments are needed for understanding whether it is possible to build an approach for successful tracking of objects and mapping them to their 3d representations on a computer. All existing algorithms have different purposes and can't be easily applied to the mentioned problem out of the box.

Towards this end, main research goals of this thesis are:
\begin{enumerate}
\item  Analyze every existing algorithm that can be applied to this problem.
\item  Take the parts of the theory beneath those algorithms and combine them together.
\item  Design a new approach for a mentioned problem based on the main seeds of the already existing algorithms. 
\end{enumerate}

\subsection{Contributions}

Methodology of this thesis is so called empirical research and it targets to achieve next goals:

\begin{itemize}
  \item Examine feature detection methods in computer vision.
  \item Examine feature classification methods in computer vision.
  \item Examine theory of stereovision (camera calibration, epipolar geometry, triangulation, pose estimation) in computer vision.
  \item Analyze theory beneath "Structure from Motion" approach.
  \item Analyze theory beneath "Tracking and Mapping" approaches.
  \item Build a framework for tracking and recognizing objects using monocular camera. Since Rubik's cube was picked as a simple shape object, using captured data it will be reconstructed and solved with an already implemented module of the framework.
\end{itemize}

\subsection{Road map}

The rest of the master thesis has the following chapters: 

\chapref*{chap:background}: Presents an overview of all related theory in computer vision: basic theory as feature detection/classification, basics of stereo vision as a camera calibration, "Structure from Motion" concept overview, "Tracking and Mapping" concept and its derivatives overview, Kalman filter explanations.

\chapref*{chap:experiments}: Contains overview of all experiments with algorithms and their implementations from the \chapref*{chap:background}. Includes descriptions of test cases, used approaches, used implementations or self written ones. Covers testing and validating results.

\chapref*{chap:contribution}: Covers a solution to the mentioned problem based on the results of experiments. Self written PTAM based approach covered and reasoned. Results are validated, pros and cons are presented.

\chapref*{chap:conclusion}: Overviews the results of the thesis and possible future work and perspectives of designed approach.

\end{document}