\documentclass[../../main.tex]{subfiles}

\graphicspath{{images/contribution/}}

\begin{document}

Design and implementation details were described in the previous two sections. Theoretical ideas and its implementation with specific technologies were covered. Now its time to describe results achieved through the long way of research.

\subsubsection*{Extraction}

Extraction was the most challenging stage of the whole process. Contours usage to find a face of a cube showed good results if the illumination condition are sufficient enough. Contours detection is very prone to the influence of illumination. If the light is falling on glossy Rubik's cube surface at specific angles the detected contours might be broken and this will fail face detection for this image. On the contrary, \ac{PTAM} like approach tracks key points with optical flow and is also affected by illumination however it is also influenced by the smoothness of motion. Both approaches can be used to succeed the extraction but it may take some time, maybe even too much for a regular user. Contours approach was chosen as more sufficient solution because of multiple reasons. The first one, it could be even applied to a limited amount of separate images. The reason for this is that contours detection does not require any motion however it needs the image with sufficient quality sufficient in order to find all needed contours. The second reason to choose it was detection speed since to extract a face the algorithm needs to capture only one image with appropriate state. 

\begin{figure} [ht!]
    \begin{center}
        \includegraphics[width=138pt]{detection_with_contours}
        \includegraphics[width=150pt]{extracted_with_contours}
        \caption{Contours approach face extraction process.}
        \label{fig:contours_approach_face_detection}
    \end{center}
\end{figure}

On the other hand, \ac{PTAM} requires to capture multiple faces in order to get their intersections that are cube's corners. This has not given wanted results because \ac{PTAM} runs bootstrap tracking to analyze motion and to get plane's information. This operation should be performed per each plane (e.g. face). To find cube's corners that will have position with respect to each other the system should compute rotations and translation from the first successfully detected plane which is the zero point for this relative system. If the algorithm fails in the middle then everything should be started from scratch. Even though, it is possible to store the current system state it have not given any results at the current stage.

\begin{figure} [ht!]
    \begin{center}
        \includegraphics[width=150pt]{detection_with_ptam}
        \includegraphics[width=140pt]{extracted_with_ptam}
        \caption{\ac{PTAM} approach face extraction process.}
        \label{fig:ptam_approach_face_detection}
    \end{center}
\end{figure}

In addition, extracted faces were checked if they were already seen before with the histogram comparison. If the face is approximately taking the same amount of space in an image then the correlation is pretty high and the code produces almost 100\% success rate. Sometimes, illumination conditions distort face colors though two different colors might be considered to be the same. In this case one face will never be confirmed and the process will never stop because it is waiting for 6 unique faces to be detected in order to go further.
To conclude, from a video perspective, contours approach can be used with any video while the success rate is close to 70\%. \ac{PTAM} gives results close to zero, the only chance to get at least somewhat results is to use real time video when operator can control camera motion per each face but not randomly rotated cube in the video.

\subsubsection*{Tracking}

In comparison with extraction, tracking task is much more suitable for \ac{PTAM} like approach. Since continuous faces detection has been failed a cube cannot be tracked with this approach. From the other point of view, cube rotation can be tracked only using single face that can be easily done with \ac{PTAM}. Generally, \ac{PTAM} like approach that has been implemented is not suitable for this because it cannot remember tracked key points when they disappear from the camera view. With the help of modified \ac{PTAM} like approach and Kalman filter it can be possible to simulate cube rotation tracking by a static camera capturing smoothly rotating cube in front of it. Stereo vision practices used in \ac{PTAM} will think the camera is rotating around the object thus rotation and translation data can be extracted and changed in order to be cubes rotation and translation representations. Kalman could be used to predict tracked key points positions when they fade away from the camera view and when the camera sees them again Kalman updates its state. This will allow to render 3D model rotation on a screen very smoothly and continuously. Described techniques are theoretically studied and proved to be possible.

\subsubsection*{Rendering}

Software rendering was successfully implemented with the described in \ref{subsec:rendering} approach. Basically it showed pretty good performance for 3D Rubik's cube model rendering, full 30 \ac{FPS}. Model can be zoomed and rotated without any performance drops. Unfortunately, software rendering cannot be used to render complex 3D models from thousands of polygons or to render a scene because it will not be possible to keep sufficient FPS. The reason is that \ac{GPU} is not used, everything is done by \ac{CPU}. Since the project is a framework, rendering library can be replaced with any other, for instance, using \ac{OpenTK} which is the most popular .NET \ac{OpenGL} wrapper. 

\begin{figure} [ht!]
    \begin{center}
        \includegraphics[width=150pt]{three_faces_view}
        \includegraphics[width=150pt]{zoomed_view}
        \caption{Rendered cube model.}
        \label{fig:rendered_cube_view}
    \end{center}
\end{figure}

\subsubsection*{Mapping and Solving}

Mapping and solving parts are tightly coupled, both of them performed well. Basically, mapping is a stage where extracted cube's faces data should be analyzed and mapped to the correspondent positions. On the other hand, mapping is also representing the storing of data from one data structure to another with a challenge to design such a data structure that will be suitable for usage with both stages: solving and rendering. This data should allow cube's layers rotation and changing cube's orientation. All the goals were accomplished thus all basic Rubik's cube operations can be performed with the model.
Solution adapters were designed to operate with the model from the mapping stage. Developed \ac{JSON} declarative notation appeared to be a very convenient tool to notate large amount of formulas in text files and the code base become a dozen times smaller or even a hundred times. Unfortunately, Rubik's cube human orientated solution algorithms may contain such manipulations that cannot be easily described within the designed notation. Nevertheless, the current implementation showed 100\% success rate.

\begin{figure} [ht!]
    \begin{center}
        \includegraphics[width=130pt]{shuffled_view}
        \includegraphics[width=130pt]{solved_view}
         \includegraphics[width=130pt]{solution_view}
        \caption{Solving random cube example.}
        \label{fig:solving_cube_view}
    \end{center}
\end{figure}

\end{document}